{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import fftconvolve\n",
    "from pydub import AudioSegment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to audio and RIR files\n",
    "\n",
    "audio_file_paths = {\n",
    "    \"Trumpet\": \"audios\\\\01b_trumpet.wav\",\n",
    "    \"Jazz\": \"audios\\\\23_jazz.wav\",\n",
    "    \"violin\": \"audios\\\\02_violin.wav\",\n",
    "    \"accordion\": \"audios\\\\20c_accordion.wav\",\n",
    "    \"guitar\": \"audios\\\\11_guitar.wav\"\n",
    "}\n",
    "\n",
    "rir_file_paths = {\n",
    "    \"small_office\": \"RIR\\\\h005_Office_Small_44txts.wav\",\n",
    "    \"Auditorium\": \"RIR\\\\h252_Auditorium_1txts.wav\",\n",
    "    \"Movie_Theater\": \"RIR\\h115_MovieTheater_1txts.wav\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion to MONO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(audio):\n",
    "    max_amplitude = np.max(np.abs(audio))\n",
    "    if max_amplitude == 0:\n",
    "        return audio \n",
    "    normalized_audio = audio / max_amplitude\n",
    "    return normalized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'audios\\\\Trumpet.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m audio_file_paths:\n\u001b[0;32m      2\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudios\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     audio \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_file(file_path)\n\u001b[0;32m      4\u001b[0m     mono_audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mset_channels(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m     temp_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_mono.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abuma\\anaconda3\\Lib\\site-packages\\pydub\\audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m _fd_or_path_or_tempfile(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m, tempfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\abuma\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[1;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(fd, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audios\\\\Trumpet.wav'"
     ]
    }
   ],
   "source": [
    "for x in audio_file_paths:\n",
    "    file_path = \"audios\\\\\" + x\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    mono_audio = audio.set_channels(1)\n",
    "    temp_file_path = \"temp_mono.wav\"\n",
    "    mono_audio.export(temp_file_path, format=\"wav\")\n",
    "    sample_rate, mono_audio_np = wavfile.read(temp_file_path)\n",
    "    mono_audio_np = mono_audio_np.astype(np.float32)\n",
    "    normalized_audio_np = normalize_audio(mono_audio_np)\n",
    "    wavfile.write(file_path, sample_rate, normalized_audio_np)\n",
    "    os.remove(temp_file_path)\n",
    "   \n",
    "    print(\"Conversion to mono completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    sample_rate, data = wavfile.read(file_path)\n",
    "    return sample_rate, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolve_audio(audio, rir):\n",
    "    if audio.ndim == 1:  # Mono\n",
    "        return fftconvolve(audio, rir, mode='full')\n",
    "    else:  # Stereo\n",
    "        return np.array([fftconvolve(channel, rir, mode='full') for channel in audio.T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abuma\\AppData\\Local\\Temp\\ipykernel_5804\\843369094.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, data = wavfile.read(file_path)\n"
     ]
    }
   ],
   "source": [
    "rirs = {key: load_audio(path)[1] for key, path in rir_file_paths.items()}\n",
    "\n",
    "for audio_key, audio_path in audio_file_paths.items():\n",
    "    sample_rate, audio_data = load_audio(audio_path)\n",
    "    for rir_key, rir_data in rirs.items():\n",
    "        processed_audio = convolve_audio(audio_data, rir_data)\n",
    "        processed_audio = np.int16(processed_audio / np.max(np.abs(processed_audio)) * 32767)\n",
    "        output_path = f\"output\\\\{audio_key}_{rir_key}.wav\"\n",
    "        wavfile.write(output_path, sample_rate, processed_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abuma\\AppData\\Local\\Temp\\ipykernel_182140\\3067238563.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, data = wavfile.read(file_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def load_audio(file_path):\n",
    "    sample_rate, data = wavfile.read(file_path)\n",
    "    return sample_rate, data\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    # Normalize the audio to the range -1 to 1\n",
    "    return audio / np.max(np.abs(audio))\n",
    "\n",
    "# Load RIR files\n",
    "rirs = {key: load_audio(path)[1] for key, path in rir_file_paths.items()}\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Process each audio file with each RIR\n",
    "for audio_key, audio_path in audio_file_paths.items():\n",
    "    sample_rate, audio_data = load_audio(audio_path)\n",
    "    for rir_key, rir_data in rirs.items():\n",
    "        processed_audio = convolve_audio(audio_data, rir_data)\n",
    "        processed_audio = normalize_audio(processed_audio)\n",
    "        processed_audio = processed_audio.astype(np.float32)  # Ensure the data is in float32 format\n",
    "        output_path = os.path.join(output_dir, f\"{audio_key}_{rir_key}.wav\")\n",
    "        wavfile.write(output_path, sample_rate, processed_audio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
